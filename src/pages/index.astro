---
import Layout from "../layouts/Layout.astro";
---

<Layout title="Live Speech">
  <div class="container mt-5">
    <h1 class="mb-4">Audio Device Selection and Transcription</h1>
    <div class="mb-3">
      <label for="audioDevices" class="form-label"
        >Select Audio Input Device:</label
      >
      <select id="audioDevices" class="form-select"></select>
    </div>
    <button id="selectDirectoryButton" class="btn btn-secondary me-2"
      >Select Recording Directory</button
    >
    <button id="startButton" class="btn btn-primary me-2"
      >Start Transcription</button
    >
    <button id="stopButton" class="btn btn-danger" disabled
      >Stop Transcription</button
    >
    <div class="mt-3">
      <div
        id="volumeBar"
        style="height: 20px; background-color: #4CAF50; width: 0%;"
      >
      </div>
    </div>
    <div
      id="transcriptionOutput"
      class="mt-3"
      style="border: 1px solid #ccc; padding: 10px; height: 300px; overflow-y: auto;"
    >
    </div>
    <div
      id="partialTranscriptionOutput"
      style="padding: 10px; height: 10rem"
      class="text-muted"
    >
    </div>
  </div>
</Layout>

<script
  is:inline
  id="config"
  data-api-key={import.meta.env.VITE_APP_SPEECHMATICS_API_KEY}></script>

<script>
  import * as base64 from "@stablelib/base64";
import { RealtimeSession } from "speechmatics";

  const apiKey = document.getElementById("config").dataset.apiKey;
  const audioDevicesSelect = document.getElementById("audioDevices");
  const selectDirectoryButton = document.getElementById(
    "selectDirectoryButton"
  );
  const startButton = document.getElementById("startButton");
  const stopButton = document.getElementById("stopButton");
  const transcriptionOutput = document.getElementById("transcriptionOutput");
  const partialTranscriptionOutput = document.getElementById(
    "partialTranscriptionOutput"
  );
  const volumeBar = document.getElementById("volumeBar");

  let session;
  let mediaRecorder;
  let directoryHandle;
  let audioChunks = [];

  async function populateAudioDevices() {
    try {
      const audioStream = await navigator.mediaDevices.getUserMedia({
        audio: true,
      });
      audioStream.getTracks().forEach((track) => track.stop());

      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputDevices = devices.filter(
        (device) => device.kind === "audioinput"
      );

      audioDevicesSelect.innerHTML = "";
      audioInputDevices.forEach((device) => {
        const option = document.createElement("option");
        option.value = device.deviceId;
        option.text =
          device.label || `Microphone ${audioDevicesSelect.length + 1}`;
        audioDevicesSelect.appendChild(option);
      });
    } catch (error) {
      console.error("Error enumerating audio devices:", error);
    }
  }

  populateAudioDevices();
  navigator.mediaDevices.addEventListener("devicechange", populateAudioDevices);

  function getSelectedAudioDevice() {
    return audioDevicesSelect.value;
  }

  let onFinish = [];

  async function startTranscription() {
    const selectedDeviceId = getSelectedAudioDevice();
    session = new RealtimeSession(apiKey);
    onFinish = [];

    let eventLogFileHandle;
    let eventLogFileStream;
    if (directoryHandle) {
      const fileName = generateFileName();
      eventLogFileHandle = await directoryHandle.getFileHandle(
        `${fileName}.jsonl`,
        { create: true }
      );
      eventLogFileStream = await eventLogFileHandle.createWritable();
      onFinish.push(() => {
        const fileToClose = eventLogFileStream;
        setTimeout(() => {
          fileToClose.close().then(
            () => {
              console.log("Closed event log file stream");
            },
            (error) => {
              console.error("Error closing event log file stream:", error);
            }
          );
          console.log("Closed file streams");
        }, 3000);
      });
    }

    function writeEvent({ event, data }) {
      const eventLog = { timestamp: new Date().toISOString(), event, data };
      const eventLogString = JSON.stringify(eventLog) + "\n";
      const eventLogBuffer = new TextEncoder().encode(eventLogString);
      eventLogFileStream?.write(eventLogBuffer);
    }

    const config = {
      transcription_config: {
        language: "th",
        // diarization: "speaker",
        // speaker_diarization_config: { max_speakers: 3 },

        operating_point: "enhanced",
        max_delay_mode: "flexible",
        max_delay: 10,
        enable_partials: true,
        transcript_filtering_config: {
          remove_disfluencies: true
        },
      },
      audio_format: { type: "file" },
      audio_events_config: { types: ["laughter", "music", "applause"] },
    };

    session.addListener("RecognitionStarted", () => {
      addLineToTranscriptionOutput("Recognition started", "text-muted");
      writeEvent({ event: "RecognitionStarted", data: {} });
    });

    session.addListener("Error", (error) => {
      console.log("session error", error);
      addLineToTranscriptionOutput(`Error: ${error.message}`, "text-danger");
      writeEvent({ event: "Error", data: { error: error.message } });
    });

    session.addListener("AddTranscript", (message) => {
      console.log("AddTranscript", message);
      addLineToTranscriptionOutput(message.metadata.transcript);
      writeEvent({ event: "AddTranscript", data: message });
    });

    session.addListener("AddPartialTranscript", (message) => {
      console.log("AddPartialTranscript", message);
      partialTranscriptionOutput.textContent = message.metadata.transcript;
      writeEvent({ event: "AddPartialTranscript", data: message });
    });

    session.addListener("EndOfTranscript", () => {
      console.log("EndOfTranscript");
      addLineToTranscriptionOutput("End of transcript", "text-muted");
      writeEvent({ event: "EndOfTranscript", data: {} });
    });

    try {
      await session.start(config);
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: { deviceId: { exact: selectedDeviceId } },
      });

      mediaRecorder = new MediaRecorder(stream, {
        mimeType: "audio/webm;codecs=opus",
        audioBitsPerSecond: 16000,
      });

      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      let ended = false;
      const buffer = new Uint8Array(analyser.frequencyBinCount);
      const frame = () => {
        if (ended) return;
        analyser.getByteFrequencyData(buffer);
        const volume =
          buffer.reduce((acc, val) => acc + val, 0) / buffer.length / 255;
        updateVolumeBar(volume);
        requestAnimationFrame(frame);
      };
      requestAnimationFrame(frame);
      onFinish.push(() => {
        ended = true;
        audioContext.close();
      });

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          session.sendAudio(event.data);
          const blob = event.data;
          blob.arrayBuffer().then((buffer) => {
            const bufferString = base64.encode(new Uint8Array(buffer));
            writeEvent({ event: "AudioData", data: bufferString });
          });
        }
      };

      mediaRecorder.start(200);
      startButton.disabled = true;
      stopButton.disabled = false;
    } catch (error) {
      console.error("Error starting transcription:", error);
    }
  }

  function stopTranscription() {
    if (mediaRecorder) {
      mediaRecorder.stop();
    }
    if (session) {
      session.stop();
    }
    startButton.disabled = false;
    stopButton.disabled = true;
    onFinish.forEach((fn) => fn());
  }

  async function selectDirectory() {
    try {
      directoryHandle = await window.showDirectoryPicker({ mode: "readwrite" });
      selectDirectoryButton.textContent = "Directory Selected";
    } catch (error) {
      console.error("Error selecting directory:", error);
    }
  }

  function generateFileName() {
    const now = new Date();
    return now.toISOString().replace(/[:T]/g, "-").slice(0, -5);
  }

  function updateVolumeBar(volume) {
    const normalizedVolume = Math.min(100, Math.max(0, volume * 100));
    volumeBar.style.width = `${normalizedVolume}%`;
  }

  function addLineToTranscriptionOutput(text, className = "") {
    const line = document.createElement("p");
    line.textContent = text;
    if (className) {
      line.className = className;
    }
    transcriptionOutput.appendChild(line);

    // Check if the user is scrolled to the bottom before auto-scrolling
    // const isScrolledToBottom =
    //   transcriptionOutput.scrollHeight - transcriptionOutput.clientHeight <=
    //   transcriptionOutput.scrollTop + 1;

    // if (isScrolledToBottom) {
      transcriptionOutput.scrollTop = transcriptionOutput.scrollHeight;
    // }
  }

  startButton.addEventListener("click", startTranscription);
  stopButton.addEventListener("click", stopTranscription);
  selectDirectoryButton.addEventListener("click", selectDirectory);
</script>
